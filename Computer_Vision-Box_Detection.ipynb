{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contour_extraction(img_path):\n",
    "    img = cv2.imread(img_path, 0) \n",
    "    (thresh, img_bin) = cv2.threshold(img, 128, 255,\n",
    "                                      cv2.THRESH_BINARY | cv2.THRESH_OTSU)  # Thresholding the image\n",
    "    img_bin = 255-img_bin  # Invert the image   \n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//40\n",
    "    ##create kernel for morphological transformation for vertical and horizontal\n",
    "    ## erosion & dilation need a kernel for the nature of operation\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))  \n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    #calculates weighted sum of two arrays\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    ##when grayscale images are converted into binary we need to apply threshold limits\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    ##Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity. \n",
    "    ##The contours are a useful tool for shape analysis and object detection and recognition\n",
    "    im2, contours, hierarchy = cv2.findContours(\n",
    "        img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclusion 7\n",
      "Exclusion 8\n",
      "Number of boxes : 4\n"
     ]
    }
   ],
   "source": [
    "contours =  contour_extraction('boxes1.jpg')\n",
    "idx = 0\n",
    "X= []\n",
    "Y = [] \n",
    "W = []\n",
    "H = [] \n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    #print(x,y,w,h)\n",
    "    ##Creating list and appending coordinates of all shapes for separation later\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    W.append(w)\n",
    "    H.append(h)\n",
    "    idx += 1\n",
    "\n",
    "idx = 1 #outer boundary  \n",
    "i = 0\n",
    "box = 0\n",
    "for c in contours:\n",
    "    idx +=1\n",
    "    i +=1\n",
    "    if idx > 2:\n",
    "        try:\n",
    "            delta =   W[(idx-1)] - W[idx] ## applying threshold limit for closer points\n",
    "            ##due to thickness in the line of boundaries, fincontours might find multiple edges on the same line \n",
    "            if(delta > 15):\n",
    "                box += 1\n",
    "        except:\n",
    "            print(\"Exclusion\",idx) ##multiple coordinates found on the same line are excluded\n",
    "print(\"Number of boxes :\",box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of boxes:  17\n"
     ]
    }
   ],
   "source": [
    "contours =  contour_extraction('boxes2.jpg')\n",
    "idx = 0\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    #print(w,h)\n",
    "    ## Applying cell boundary limit to define & search for approx cell size in the table\n",
    "    if (w > 80 and h > 20): \n",
    "        idx += 1\n",
    "#         new_img = img[y:y+h, x:x+w]\n",
    "#         plt.figure()\n",
    "#         plt.imshow(new_img)\n",
    "#         print(\"done\")\n",
    "print(\"Number of boxes: \",idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of boxes:  71\n"
     ]
    }
   ],
   "source": [
    "contours =  contour_extraction('table1.jpg')\n",
    "idx = 0\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    #print(w,h)\n",
    "    if (w > 40 and h > 20):\n",
    "        idx += 1\n",
    "#         new_img = img[y:y+h, x:x+w]\n",
    "#         plt.figure()\n",
    "#         plt.imshow(new_img)\n",
    "#         print(\"done\")\n",
    "print(\"Number of boxes: \",idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
